{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dce501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_CUD_baseline(subs_list):\n",
    "        \n",
    "    #subs to be excluded (only MM) because they had cannabis use disorder at baseline (exclusion criterium)\n",
    "    excluded_subs = ['MM_014','MM_188','MM_197','MM_217','MM_228','MM_239','MM_241']\n",
    "    \n",
    "    #get only subjects that aren't those of any of the excluded subjects\n",
    "    final_subs_list = [sub for sub in subs_list if sub not in excluded_subs]\n",
    "        \n",
    "    return final_subs_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subs():\n",
    "    \n",
    "    #get subs for each group and timepoint\n",
    "    HC_subs_baseline_paths = glob.glob(f'../../../sub-HC*/ses-baseline')\n",
    "    HC_subs_baseline = ['HC_' + path.split('/')[3].split('-HC')[1] for path in HC_subs_baseline_paths]\n",
    "    \n",
    "    MM_subs_baseline_paths = glob.glob(f'../../../sub-MM*/ses-baseline')\n",
    "    MM_subs_baseline = set(['MM_' + path.split('/')[3].split('-MM')[1] for path in MM_subs_baseline_paths])\n",
    "\n",
    "    MM_subs_1year_paths = glob.glob(f'../../../sub-MM*/ses-1year')\n",
    "    MM_subs_1year = set(['MM_' + path.split('/')[3].split('-MM')[1] for path in MM_subs_1year_paths])\n",
    "    \n",
    "    #divide MM subs by paired or not and remove CUD baseline subs\n",
    "    MM_subs_paired = rm_CUD_baseline(list(MM_subs_baseline.intersection(MM_subs_1year)))\n",
    "    \n",
    "    MM_subs_only_baseline = rm_CUD_baseline(list(MM_subs_baseline.difference(MM_subs_1year)))\n",
    "    \n",
    "    MM_subs_only_1year = rm_CUD_baseline(list(MM_subs_1year.difference(MM_subs_baseline)))\n",
    "    \n",
    "    MM_subs_single = MM_subs_only_baseline + MM_subs_only_1year\n",
    "    \n",
    "    #put all subs lists together as a dictionary\n",
    "    subs_all_dict = {'MM_single':MM_subs_single, 'MM_paired':MM_subs_paired, 'HC_baseline':HC_subs_baseline}\n",
    "\n",
    "    return subs_all_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27adf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indiv_subs_df(group, subs_list):\n",
    "    \n",
    "    #dataframe to add columns to for each subject\n",
    "    ses = group.split('_')[-1]\n",
    "    \n",
    "    df_data = {\n",
    "    'subs': subs_list,\n",
    "    'session': [ses] * len(subs_list)\n",
    "    }\n",
    "    \n",
    "    df_subs = pd.DataFrame(df_data)\n",
    "    \n",
    "    \n",
    "    #load the non-imaging data\n",
    "    non_img_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/MMJ-Processed_data-2022_05_27-13_58-6858bbe.csv\",low_memory=False)\n",
    "\n",
    "    simple_additions = [('SBJ.CHR.Sex','Sex'),(\"SBJ.INT.Age\",'Age'),\n",
    "                        (\"SBJ.CHR.Race\",'Race'), (\"SBJ.CHR.Ethnicity\",'Ethnicity'),\n",
    "                        (\"SBJ.INT.Education_years\",'Education years'),\n",
    "                        ('SSS.CHR.Primary_condition','Condition'),\n",
    "                        (\"SBJ.CHR.Handedness\",'Handedness')]\n",
    "                        \n",
    "    \n",
    "    for orig_name, col_name in simple_additions:\n",
    "            \n",
    "        dict_map = non_img_data.groupby(\"IDS.CHR.Subject\")[orig_name].agg(\"first\").to_dict()\n",
    "\n",
    "        if orig_name == 'SBJ.CHR.Race':\n",
    "            for sub, race in dict_map.items():\n",
    "                if race == 'Caucasian':\n",
    "                    dict_map[sub] = 'White'\n",
    "                elif race == 'African American':\n",
    "                    dict_map[sub] = 'Black'\n",
    "                elif race == 'Asian':\n",
    "                    dict_map[sub] = 'Other'\n",
    "                elif race == 'Multi-racial':\n",
    "                    dict_map[sub] = 'Other'\n",
    "                elif race == 'Pacific Islander':\n",
    "                    dict_map[sub] = 'Other'\n",
    "                    \n",
    "        if orig_name == 'SSS.CHR.Primary_condition':\n",
    "            for sub, condition in dict_map.items():\n",
    "                if condition == 'Affective Disorder (Depression/Anxiety)':\n",
    "                    dict_map[sub] = 'Depression/anxiety symptoms'\n",
    "                elif condition == 'Insomnia':\n",
    "                    dict_map[sub] = 'Insomnia symptoms'\n",
    "                elif condition == 'Pain':\n",
    "                    dict_map[sub] = 'Pain symptoms'\n",
    "\n",
    "        df_subs[col_name] = df_subs['subs'].map(dict_map)\n",
    "                \n",
    "    return df_subs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e289a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(group, df):\n",
    "    \n",
    "    #explicitly specify which columns are categorical and which are numerical\n",
    "    categorical_columns = ['Sex', 'Race', 'Ethnicity', 'Condition', 'Handedness']\n",
    "    numerical_columns = ['Age', 'Education years']\n",
    "\n",
    "    #initialize a list to store the formatted results\n",
    "    summary_list = []\n",
    "\n",
    "    #calculate the total count of individuals\n",
    "    total_count = len(df)\n",
    "\n",
    "    #summary statistics for numerical columns\n",
    "    for column in numerical_columns:\n",
    "        median_value = df[column].median()\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        result = f'{median_value:.1f} ({iqr:.1f})'\n",
    "        summary_list.append({'Items': f'{column}, median (IQR)', 'Levels': np.nan, f'{group}': result})\n",
    "\n",
    "    #summary statistics for categorical columns\n",
    "    for column in categorical_columns:\n",
    "        counts = df[column].value_counts()\n",
    "        proportions = df[column].value_counts(normalize=True)\n",
    "        \n",
    "        #reorder the categories based on the custom order and fill in missing values as 0\n",
    "        if column == 'Race':\n",
    "            custom_order = ['Black', 'White', 'Other']\n",
    "            counts = counts.reindex(custom_order, fill_value=0)\n",
    "            proportions = proportions.reindex(custom_order, fill_value=0)\n",
    "            \n",
    "        if column == 'Ethnicity':\n",
    "            custom_order = ['Hispanic or Latino', 'Not Hispanic or Latino']\n",
    "            counts = counts.reindex(custom_order, fill_value=0)\n",
    "            proportions = proportions.reindex(custom_order, fill_value=0)\n",
    "        \n",
    "        if column == 'Condition':\n",
    "            custom_order = ['Depression/anxiety symptoms', 'Insomnia symptoms', 'Pain symptoms', 'Healthy control']\n",
    "            counts = counts.reindex(custom_order, fill_value=0)\n",
    "            proportions = proportions.reindex(custom_order, fill_value=0)\n",
    "\n",
    "            \n",
    "        for category in counts.index:\n",
    "            count = counts[category]\n",
    "            percentage = proportions[category] * 100\n",
    "            result = f'{count} ({percentage:.1f})'\n",
    "            summary_list.append({'Items': f'{column}, n (%)', 'Levels': category, f'{group}': result})\n",
    "    \n",
    "    \n",
    "    #move education years to correct spot\n",
    "    item_to_move = summary_list.pop(1)\n",
    "    summary_list.insert(8, item_to_move)\n",
    "    \n",
    "    #move age to correct spot\n",
    "    item_to_move2 = summary_list.pop(0)\n",
    "    summary_list.insert(2, item_to_move2)\n",
    "    \n",
    "            \n",
    "    #create a DataFrame from the summary list\n",
    "    summary_df = pd.DataFrame(summary_list)\n",
    "\n",
    "    #create the count row\n",
    "    count_row = pd.DataFrame([{'Items': 'n', 'Levels': np.nan, f'{group}': total_count}])\n",
    "\n",
    "    #concatenate the count row with the summary DataFrame\n",
    "    summary_df = pd.concat([count_row, summary_df], ignore_index=True)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#report result of shapiro-wilks test\n",
    "def is_normal(data):\n",
    "    stat, p_value = stats.shapiro(data)\n",
    "    return p_value > 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476531c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_statistical_comparisons(groups,subs_all_df_dict):\n",
    "    \n",
    "    #save p-values in a dictionary for multiple comparisons\n",
    "    p_values_dict = {}\n",
    "\n",
    "    numerical_columns = ['Age', 'Education years']\n",
    "    categorical_columns = ['Sex', 'Race', 'Ethnicity', 'Condition', 'Handedness']\n",
    "    \n",
    "    for num_column in numerical_columns:\n",
    "        \n",
    "        input_test = [subs_all_df_dict[group][num_column].to_list() for group in groups]\n",
    "        \n",
    "        if all(is_normal(subs_all_df_dict[group][num_column]) for group in groups):\n",
    "            print(f'\\n{num_column} is normal, running ANOVA')\n",
    "            anova_result = stats.f_oneway(*input_test)\n",
    "            print(\"ANOVA result:\", anova_result)\n",
    "            p_values_dict[num_column] = anova_result.pvalue\n",
    "\n",
    "        else:\n",
    "            print(f'\\n{num_column} is not normal, running a Kruskal-Wallis H-test')\n",
    "            kruskal_result = stats.kruskal(*input_test)\n",
    "            print(\"Kruskal-Wallis H-test result:\", kruskal_result)\n",
    "            p_values_dict[num_column] = kruskal_result.pvalue\n",
    "\n",
    "            \n",
    "    print(\"\\nIf a Fisher exact test is required due to limited observations in a group's category (less than 5), it will be conducted in R since Python's scipy library does not offer the Fisher exact test for a contingency table of greater than 2x2 at the moment. In those cases, the counts needed for the Fisher exact test will be calculated and printed to be copied into the R code.\")\n",
    "    for cat_column in categorical_columns:\n",
    "        input_test = [subs_all_df_dict[group][cat_column].value_counts().values.tolist() for group in groups]\n",
    "        \n",
    "        #account for missing categories\n",
    "        if cat_column == 'Ethnicity':\n",
    "            input_test[1].append(0)\n",
    "        \n",
    "        #account for healthy control not having conditions by definition and thus not being included in this test\n",
    "        if cat_column == 'Condition':\n",
    "            input_test.pop(0)\n",
    "                    \n",
    "        if any(el < 5 for sublist in input_test for el in sublist):\n",
    "            print(f'\\nFisher exact test is required for {cat_column}')\n",
    "            print('Here are the values for R:', [el for sublist in input_test for el in sublist])\n",
    "            p_values_dict[cat_column] = np.nan\n",
    "        \n",
    "        else:\n",
    "            print(f'\\nChi-squared test is possible for {cat_column}')\n",
    "            chi2_result = stats.chi2_contingency(input_test)\n",
    "            print(\"Chi-squared test result:\", chi2_result)\n",
    "            p_values_dict[cat_column] = chi2_result.pvalue\n",
    "\n",
    "            \n",
    "    return p_values_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_statistical_comparisons():\n",
    "    \n",
    "    groups = ['HC_baseline', 'MM_single', 'MM_paired']\n",
    "    \n",
    "    #create df of all subs with relevant demographics\n",
    "    subs_all_dict = get_all_subs()\n",
    "    \n",
    "    subs_all_df_dict = defaultdict(pd.DataFrame)\n",
    "    \n",
    "    summary_dfs = []\n",
    "    \n",
    "    for group in groups:\n",
    "        #get individual dataframes per group with relevant demographics\n",
    "        indiv_subs_df = create_indiv_subs_df(group, subs_all_dict[group])\n",
    "        subs_all_df_dict[group] = indiv_subs_df        \n",
    "        \n",
    "        #create summary tables\n",
    "        indiv_summary_df = create_summary_table(group, indiv_subs_df)\n",
    "        summary_dfs.append(indiv_summary_df)\n",
    "    \n",
    "    #make shared summary statistics dataframe\n",
    "    summary_df = summary_dfs[0].iloc[:, :2].copy()\n",
    "    \n",
    "    for indiv_summary_df in summary_dfs:\n",
    "        summary_df = pd.concat([summary_df, indiv_summary_df.iloc[:, 2]], axis=1)\n",
    "\n",
    "    display(summary_df)\n",
    "    \n",
    "    #run statistical comparisons for numerical variables\n",
    "    p_values_dict = run_statistical_comparisons(groups, subs_all_df_dict)\n",
    "    \n",
    "    print(\"\\nHere are the p-values from the statistical comparisons:\")\n",
    "    for key, value in p_values_dict.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return p_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa80b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_dict = set_up_statistical_comparisons()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we will take the p-values from above and those from the Fisher tests run in R to do multiple comparison correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN with R p-values\n",
    "p_values_dict['Race'] = 0.1367\n",
    "p_values_dict['Ethnicity'] = 0.2297\n",
    "p_values_dict['Handedness'] = 0.8094\n",
    "\n",
    "#extract p-values and variables they correspond to (keys)\n",
    "variables = list(p_values_dict.keys())\n",
    "p_values_list = list(p_values_dict.values())\n",
    "\n",
    "#apply FDR correction using the Benjamini-Hochberg procedure\n",
    "corrected_results = multipletests(p_values_list, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "#extract corrected p-values and rejection decisions\n",
    "corrected_p_values = corrected_results[1]\n",
    "reject_null_hypothesis = corrected_results[0]\n",
    "\n",
    "#map the corrected results back to the corresponding variables:\n",
    "corrected_p_values_dict = dict(zip(variables, corrected_p_values))\n",
    "reject_null_hypothesis_dict = dict(zip(variables, reject_null_hypothesis))\n",
    "\n",
    "#output the results\n",
    "print(\"Here are the results of the multiple comparison correction:\")\n",
    "print(\"Corrected p-values:\", corrected_p_values_dict)\n",
    "print(\"Reject null hypothesis:\", reject_null_hypothesis_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
